---
title: "Yaw belt, Pitch forearm and Pitch belt are the best predictors of the quality of a dumbbell biceps curl."
subtitle: "Practical Machine Learning project"
author: "Elmer Ore"
output: html_document
---

## Executive Summary

In this report I aim to replicate the findings of the Human Activity Recognition experiment and be able to identify how well the 6 participants did the dumbbell biceps curl against common mistakes being recorded.  By analyzing the data provided I excluded some predictors that did not have a relationship wih the outcome or predictors with high number of null or empty values.  For this classification project I created a 'recipe' to prepare the data and decided to use Random Forest as the model to help predict the participants activities.  From this model **I found that 26 predictors shows the highest accuracy of 99.57% for out-of-bag error.**  Finally, I included the list of the top 20 variables with the highest impact in the final model.

## Exploratory Analysis

- I identified mostly null or empty predictors, I decided 97% as a cutoff value.
- I also identified fields not useful in predicting how the exercise was done.  I decided to remove the variables: unique sequential number, user name, timestamps, and window information.

```{r setup, echo=TRUE, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
library(dplyr)

# Getting original data
training <- read.csv(file="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
validation <- read.csv(file="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")

missing_function <- function(vector){
  ##The ifelse returns TRUE if the element in the vector is NA, NULL, or ""
  x <- ifelse(is.na(vector)|vector == ""|is.null(vector), TRUE, FALSE)
  
  ##Returns the sum of boolean vector (FALSE = 0, TRUE = 1)
  return(sum(x))
}

fields_remove <- tibble(variable = colnames(training),
                        total_missing = sapply(training, missing_function),
                        rate = total_missing/nrow(training))

# Using 97% as a cutoff for removing null or empty variables.
fields_remove <- fields_remove %>% filter(rate > 0.97) %>% select(variable)

# Adding manual variables to the fields to remove not related to the outcome.
fields_remove <- bind_rows(fields_remove, 
                           data.frame(variable = c("X", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"), 
                                      stringsAsFactors = FALSE))

fields_remove <- as.vector(fields_remove$variable)

```

## Reproducible Research

- I decided to use **recipes**, to increase the reproducibility of the analysis.
- I removed the predictors identified in the exploratory analysis as not useful for the model.
- I excluded near zero variance and correlated predictors.
- I converted all factor variables into dummy variables, except the outcome.
- I centered and scaled the rest of the variables.
\newline

```{r message=FALSE, results='hide', warning=FALSE}
library(dplyr)
library(recipes)

#creation of the recipe.
train_recipe <- recipe(classe ~ ., data = training) %>%
  step_rm(one_of(fields_remove)) %>%
  step_nzv(all_predictors()) %>%
  step_corr(all_numeric()) %>%
  step_dummy(all_nominal(), - all_outcomes()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) 

# preparing the recipe
trained_recipe <- prep(train_recipe, training = training)

# executing the recipe in both datasets.
train_data <- bake(trained_recipe, new_data = training)
exam_data <- bake(trained_recipe, new_data = validation)

```

## Model Selection

I decided to use 10-fold cross validation due to the size of the training set and number of predictors available. 
In terms of the model, I decided to use the Random Forests model for this classification problem.  

```{r message=FALSE, results='hide', warning=FALSE, cache=TRUE}
library(caret)
library(parallel)
library(doParallel)

# Configuring parallel processing
cluster <- makeCluster(5) # convention to leave 1 core for OS
registerDoParallel(cluster)

# Configuring parameters, 10 fold cross validation.
fitControl <- trainControl(method = "cv",
                           number = 10,
                           allowParallel = TRUE)

set.seed(778)
#executing the model
fit <- train(classe~., method="rf",data=train_data, trControl = fitControl)

# De-register parallel processing cluster
stopCluster(cluster)
registerDoSEQ()

```

## Model Validation

Since cross-validation was used, I calculated the average accuracy of the out-of-sample samples. 

```{r message=FALSE, results='show'}
# average of out-of-sample accuracy for the 10 CV samples.
mean(fit$resample$Accuracy)
```

However, the out-of-sample accuracy is bias towards the training set.  Since I used Random Forest there is something called 'out of bag error' which is intended to compensate for this and can be more accurate.  It shows that the accuracy of the model is **`r round(fit$modelInfo$oob(fit$finalModel)[1]*100,2)`%**.

```{r message=FALSE, results='show'}
# Out-of-bag error from random forest, to compensate from CV bias.
fit$modelInfo$oob(fit$finalModel)
```

Here are the list of the top 20 predictors with highest impact in the final model.

```{r message=FALSE, echo=FALSE, warning=FALSE, fig.height = 4, fig.width = 6} 
library(caret)
library(ggplot2)

list_variables <- varImp(fit, scale = FALSE)
ggplot(list_variables, top=20) + 
       ggtitle("Predictors with highest impact in model")
```

The image below shows that when the model randomly selected 26 predictors it obtained the highest accuracy.

```{r message=FALSE, echo=FALSE, warning=FALSE, fig.height = 4, fig.width = 6} 
library(ggplot2)

ggplot(fit) +
  ggtitle("26 predictors shows the highest accuracy")
```

## Conclusions

The model shows:

- The Random Forest model restulted with an out-of-bag accuracy of **`r round(fit$modelInfo$oob(fit$finalModel)[1]*100,2)`%**.
- The most important predictors identified are: Yaw belt, Pitch forearm and Pitch belt.
- The model identified 26 randomly selected predictors as the combination with the highest accuracy.

## References

- Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. [Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements](http://groupware.les.inf.puc-rio.br/work.jsf?p1=10335). Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6.
- The data used for this project comes from <http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har>.
- The function to identify null or empty values was found in this post <https://stackoverflow.com/questions/53036693/handle-missingness-including-null-values-in-r>.